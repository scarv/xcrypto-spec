% =============================================================================

\subsection{More specific,  low(er)-level points}
\label{appx:discuss:lo}

\begin{itemize}

\item \XCID instruction mnemonics follow a (somewhat) consistent scheme; 
      they all include a domain-separating prefix \VERB[RV]{xc}, and, if
      need be, a suffix intended to identify specific variants.  These 
      include
      \[
      \begin{array}{lcl}
      \VERB[RV]{i} &:& \mbox{immediate (vs. register)   }        \\
      \VERB[RV]{u} &:& \mbox{updating  (vs. overwriting)}        \\
      \VERB[RV]{h} &:& \mbox{high}                               \\
      \VERB[RV]{l} &:& \mbox {low}                               \\
      \VERB[RV]{b} &:& \mbox     {byte oriented}                 \\
      \VERB[RV]{h} &:& \mbox{half-word oriented}                 \\
      \VERB[RV]{w} &:& \mbox     {word oriented}                 \\
      \VERB[RV]{x} &:& \mbox{a size, length, or count parameter} \\
      \end{array}
      \]
\item Although they share a memory interface, there is no requirement for
      the host core and co-processor to share an address space.  Indeed,
      it is easy to imagine cases where using disjoint address spaces is
      useful; examples include use of
      a) an OTP-style memory for key storage, 
         or
      b) a (uncached) scratch-pad memory,
      by the co-processor alone.

\end{itemize}

% =============================================================================

\subsection{More  generic, high(er)-level points}
\label{appx:discuss:hi}

\begin{itemize}

\item Lee and Fiskiran introduce (e.g., see~\cite{SCARV:LeeFis:05}) the PLX
      design, which, among other concepts, supports 
      a) sub-word parallelism (cf. packed, or SWAR-like operations),
         and
      b) word size scalability (or data-path scalability).
      First, 
      note that a fully sub-word parallel ISA is orthogonal wrt. all useful
      sub-word sizes; PLX supports $n$-byte sub-word sizes for sane $n$.
      Second,
      note that, in a sense, RISC-V is word size scalable: it can cater for
      implementations that, e.g., have a $32$-bit instructions but a $32$-,
      $64$-, or $128$-bit $\GPR$ register file (and so also address space). 

      \begin{itemize}
      \item Within instruction class $2.4$, \XCID considers sub-{\em byte} 
            (e.g., $4$-bit), sub-word sizes; doing so is motivated, e.g., 
            by their utility in some classes of light-weight block cipher.  

      \item Currently, \XCID does not explore the potential of a scalable 
            word size: it assumes a fixed $\XCLEN = 32$, though retaining
            compatibility wrt. $\RVXLEN \in \SET{ 32, 64, 128 }$.

            Doing so {\em is} clearly plausible: one could imagine
            a) equipping $\SPR{mxcsr}$ with a field to reflect $\XCLEN$,
               then
            b) making selected alterations to instruction specifications,
               for example

            \begin{itemize}
            \item when $\XCLEN \neq \RVXLEN$, 
                  some instructions
                  (e.g., in class $1$:   \VERB[RV]{xc.gpr2xcr} and \VERB[RV]{xc.gpr2xcr})
                  would need a specification that caters for the differing 
                  sizes of registers in $\XCR$ and $\GPR$,
            \item for $\XCLEN > 32$, 
                  some instructions
                  (e.g., class $1.1$: \VERB[RV]{xc.rngsamp})
                  imply a significant implementation overhead,
            \item for $\XCLEN > 32$, 
                  some instructions
                  (e.g., class $2.1$: \VERB[RV]{xc.scatter.b} and \VERB[RV]{xc.gather.b})
                  would be to be (re)specified in a more general form,
                  and
            \item for $\XCLEN > 32$, 
                  some instructions
                  (e.g., class $3.1$: \VERB[RV]{xc.aesmix})
                  would be nonsensical, i.e., need removing or replacing.
            \end{itemize}

            \noindent
            Beyond this, however, the question is whether it has any value;
            this is harder to answer, so {\em may} represent an interesting 
            experiment to consider more concretely.
            For example, $\XCLEN > 32$ would apply naturally to, and hence
            represent an advantage to instructions in class $2.4$ (e.g.,
            \VERB[RV]{xc.add.2}).  However, it is unclear whether such an
            advantage would be greater than just considering $\RVXLEN > 32$
            {\em without} \XCID at all, or indeed alternative paradigms 
            such as the standard V~\cite[Section 17]{SCARV:RV:ISA:I:17} 
            extension.

      \end{itemize}

\item Consider a general case, wherein a given ISA has instruction formats
      that allow access to $n$ general-purpose registers, st. 
      $
      n = s + d
      $ 
      for $s$ sources and $d$ destinations, meaning an associated encoding 
      must somehow specify $n$ register addresses.  The special case
      $
      n = 3 = 2 + 1 
      $
      is common, and adopted by RISC-V, but it should nevertheless be clear
      that {\em other} cases can also be useful.  A common ``wrinkle'' in a 
      strict $3$-address case is (full) $( w \times w )$-bit multiplication, 
      which produces a $(2 \cdot w )$-bit product and therefore demands use 
      of {\em two} $w$-bit destination registers.
   
      One of the strategies underlying \XCID is support for larger $s$ and
      $d$.  This is rationalised by a (ideally positive) trade-off between
      a) increased register file complexity, as a result of the requirement
         to support $n$ ports, or, alternatively, multi-cycle operations,
         vs.
      b) increased register file bandwidth.
      The latter enables each instruction to perform more, or richer forms 
      of computation, aligning well with the demands of many cryptographic 
      workloads: this essentially matches the concept
      Lee et al.~\cite{SCARV:LeeYanShi:04}
      describe as data-rich execution, supported, in their terminology, by 
      Multi-word Operands, Multi-word Results (MOMR)
      capable computational infrastructure.

      Even {\em if} said trade-off is acceptable, however, it also implies 
      some challenges wrt. instruction encoding.  There seem to be several 
      possible options:

      \begin{enumerate}
      \item One could make all  register addresses {\em explicit}.
            For example, XS1 uses a long (i.e., $32$-bit) $6$-address 
            instruction format~\cite[Page 246]{SCARV:XS1:09} 
            to encode
            \VERB{lmul}~\cite[Page 146]{SCARV:XS1:09}.
      \item One could make some register addresses {\em implicit}.  
            For example, the x86 $( 32 \times 32 )$-bit multiplication 
            instruction 
            \VERB{mul}~\cite[Page 4-144--4-145]{SCARV:X86:2:18} 
            makes implicit uses of \VERB{edx} and \VERB{edx} as destinations.
      \item One could make some register addresses {\em implied}.
            For example, this approach has been considered within the
            specific context of support cryptography: 
            Lee and Choi~\cite{SCARV:LeeCho:08} propose Register File
            Extension for Multi-word and Long-word Operation (RFEMLO), 
            where a group of $n$ contiguous registers is identified by 
            one register address plus a group size (or level in their terminology): 
            address $i$ and level $n$ implies use of registers
            \[
            i, i + 1, i + 2, \ldots i + 2^n - 1 .
            \]
            Note that this approach potentially causes an issue wrt.
            registers with specific semantics.  For example, in many
            RISC-like ISAs (including RISC-V), $\GPR[0]$ is fixed to 
            $0$; it may be difficult to include or exclude $\GPR[0]$ 
            in a group as need be.
      \item One could make some register addresses {\em overloaded}.
            For example, ARMv7-A includes a so-called ``unsigned multiply,
            accumulate accumulate'' instruction 
            \VERB{umaal}~\cite[Section A8.8.255]{SCARV:ARMv7_M:17} 
            whose format {\em suggests} $n = 4 = 2 + 2$ but in fact 
            reuses the two destination as additional sources.
      \end{enumerate}
      
      \noindent
      Note that several of these approaches have an implication for the
      difficulty of register allocation; the obvious example is that of
      implicit register addresses.  Likewise, there are various generic
      ways to mitigate the encoding pressure (i.e., the availability of 
      at most $w$ bits) given an approach.  For example one could
      
      \begin{enumerate}
      \item restrict access to some subset of the register file 
            (cf. ARM Thumb or RV32E) 
            thereby reducing the number of bits required to encode each  
            register address,
            or
      \item use some form of instruction prefix.
      \end{enumerate}

\item The $\XCR$ register file capacity (i.e., the number of constituent
      registers) is a trade-off between quite a number of factors, e.g.,

      \begin{itemize}
      \item increased area, and complexity stemming from implementation
            of the register file,
      \item use of a $16$-element $\XCR$ register file in conjunction
            with RV32E~\cite[Section 3]{SCARV:RV:ISA:I:17} yielding a 
            similar footprint (wrt. this resource at least) to RV32I,
      \item a domain-specific remit suggesting a smaller capacity is 
            viable,
      \item   domain-specific workloads suggest more value from larger 
            registers (i.e., word size), not necessarily larger register
            file capacity,
      \item a smaller capacity reducing instruction encoding pressure.
      \end{itemize}

\end{itemize}

% =============================================================================
