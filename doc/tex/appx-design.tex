% =============================================================================

%
% TODO: FAQ items
%
% - Why a "general purpose" ISA? What does this mean wrt. "special purpose"?
%
%


\begin{description}

\item[Is there any logic behind the \XCID instruction mnemonics?]
      \XCID instruction mnemonics follow a (somewhat) consistent scheme; 
      they all include a domain-separating prefix \VERB[RV]{xc}, and, if
      need be, a suffix intended to identify specific variants.  These 
      include
      \[
      \begin{array}{lcl}
      \VERB[RV]{i} &:& \mbox{immediate (vs. register)   }        \\
      \VERB[RV]{u} &:& \mbox{updating  (vs. overwriting)}        \\
      \VERB[RV]{h} &:& \mbox{high}                               \\
      \VERB[RV]{l} &:& \mbox {low}                               \\
      \VERB[RV]{b} &:& \mbox     {byte oriented}                 \\
      \VERB[RV]{h} &:& \mbox{half-word oriented}                 \\
      \VERB[RV]{w} &:& \mbox     {word oriented}                 \\
      \VERB[RV]{x} &:& \mbox{a size, length, or count parameter} \\
      \end{array}
      \]

\item[What restrictions exist wrt. the \XCID memory interface?]
      Although they share a memory interface, there is no requirement for
      the host core and co-processor to share an address space.  Indeed,
      it is easy to imagine cases where using disjoint address spaces is
      useful; examples include use of
      a) an OTP-style memory for key storage, 
         or
      b) a (uncached) scratch-pad memory,
      by the co-processor alone.

\item[Why not generalise the \XCID word size, e.g., in line with the base ISA?]
      Lee and Fiskiran introduce (e.g., see~\cite{SCARV:LeeFis:05}) the PLX
      design, which, among other concepts, supports 
      a) sub-word parallelism (cf. packed, or SWAR-like operations),
         and
      b) word size scalability (or data-path scalability).
      First, 
      note that a fully sub-word parallel ISA is orthogonal wrt. all useful
      sub-word sizes; PLX supports $n$-byte sub-word sizes for sane $n$.
      Second,
      note that, in a sense, RISC-V is word size scalable: it can cater for
      implementations that, e.g., have a $32$-bit instructions but a $32$-,
      $64$-, or $128$-bit $\GPR$ register file (and so also address space). 

      \begin{itemize}
      \item Within instruction class $2.4$, \XCID considers sub-{\em byte} 
            (e.g., $4$-bit), sub-word sizes; doing so is motivated, e.g., 
            by their utility in some classes of light-weight block cipher.  

      \item Currently, \XCID does not explore the potential of a scalable 
            word size: it assumes a fixed $\XCLEN = 32$, though retaining
            compatibility wrt. $\RVXLEN \in \SET{ 32, 64, 128 }$.

            Doing so {\em is} clearly plausible: one could imagine
            a) equipping $\SPR{mxcsr}$ with a field to reflect $\XCLEN$,
               then
            b) making selected alterations to instruction specifications,
               for example

            \begin{itemize}
            \item when $\XCLEN \neq \RVXLEN$, 
                  some instructions
                  (e.g., in class $1$:   \VERB[RV]{xc.gpr2xcr} and \VERB[RV]{xc.gpr2xcr})
                  would need a specification that caters for the differing 
                  sizes of registers in $\XCR$ and $\GPR$,
            \item for $\XCLEN > 32$, 
                  some instructions
                  (e.g., class $1.1$: \VERB[RV]{xc.rngsamp})
                  imply a significant implementation overhead,
            \item for $\XCLEN > 32$, 
                  some instructions
                  (e.g., class $2.1$: \VERB[RV]{xc.scatter.b} and \VERB[RV]{xc.gather.b})
                  would be to be (re)specified in a more general form,
                  and
            \item for $\XCLEN > 32$, 
                  some instructions
                  (e.g., class $3.1$: \VERB[RV]{xc.aesmix})
                  would be nonsensical, i.e., need removing or replacing.
            \end{itemize}

            \noindent
            Beyond this, however, the question is whether it has any value;
            this is harder to answer, so {\em may} represent an interesting 
            experiment to consider more concretely.
            For example, $\XCLEN > 32$ would apply naturally to, and hence
            represent an advantage to instructions in class $2.4$ (e.g.,
            \VERB[RV]{xc.add.2}).  However, it is unclear whether such an
            advantage would be greater than just considering $\RVXLEN > 32$
            {\em without} \XCID at all, or indeed alternative paradigms 
            such as the standard V~\cite[Section 17]{SCARV:RV:ISA:I:17} 
            extension.

      \end{itemize}

\item[Why does \XCID deviate from the standard RISC-V encoding formats?]
      A simple instruction encoding scheme is desirable for many reasons:
      It can reduce design complexity, reduce decoder gate counts and
      aids encoding assignment.

      If a scheme is adopted too early however, or adhered to without
      exception, it can become restrictive and hamper development of
      instructions which do not naturally fit within it.

      \XCID places more importance on inclusion of appropriate functionality
      than how that functionality is encoded. Indeed, some of the most
      important instructions in \XCID cannot possibly fit into the standard
      RISC-V encoding scheme. 
      Also, while uniformity of encodings has a positive impact on decoder
      size, in absolute terms the instruction decode logic is small when
      compared to the rest of a core.

\item[Why does \XCID deviate from a $3$-address instruction format?]
      Consider a general case, wherein a given ISA has instruction formats
      that allow access to $n$ general-purpose registers, st. 
      $
      n = s + d
      $ 
      for $s$ sources and $d$ destinations, meaning an associated encoding 
      must somehow specify $n$ register addresses.  The special case
      $
      n = 3 = 2 + 1 
      $
      is common, and adopted by RISC-V, but it should nevertheless be clear
      that {\em other} cases can also be useful.  A common ``wrinkle'' in a 
      strict $3$-address case is (full) $( w \times w )$-bit multiplication, 
      which produces a $(2 \cdot w )$-bit product and therefore demands use 
      of {\em two} $w$-bit destination registers.
   
      One of the strategies underlying \XCID is support for larger $s$ and
      $d$.  This is rationalised by a (ideally positive) trade-off between
      a) increased register file complexity, as a result of the requirement
         to support $n$ ports, or, alternatively, multi-cycle operations,
         vs.
      b) increased register file bandwidth.
      The latter enables each instruction to perform more, or richer forms 
      of computation, aligning well with the demands of many cryptographic 
      workloads: this essentially matches the concept
      Lee et al.~\cite{SCARV:LeeYanShi:04}
      describe as data-rich execution, supported, in their terminology, by 
      Multi-word Operands, Multi-word Results (MOMR)
      capable computational infrastructure.

      Even {\em if} said trade-off is acceptable, however, it also implies 
      some challenges wrt. instruction encoding.  There seem to be several 
      possible options:

      \begin{enumerate}
      \item One could make all  register addresses {\em explicit}.
            For example, XS1 uses a long (i.e., $32$-bit) $6$-address 
            instruction format~\cite[Page 246]{SCARV:XS1:09} 
            to encode
            \VERB{lmul}~\cite[Page 146]{SCARV:XS1:09}.
      \item One could make some register addresses {\em implicit}.  
            For example, the x86 $( 32 \times 32 )$-bit multiplication 
            instruction 
            \VERB{mul}~\cite[Page 4-144--4-145]{SCARV:X86:2:18} 
            makes implicit uses of \VERB{edx} and \VERB{edx} as destinations.
      \item One could make some register addresses {\em implied}.
            For example, this approach has been considered within the
            specific context of support cryptography: 
            Lee and Choi~\cite{SCARV:LeeCho:08} propose Register File
            Extension for Multi-word and Long-word Operation (RFEMLO), 
            where a group of $n$ contiguous registers is identified by 
            one register address plus a group size (or level in their terminology): 
            address $i$ and level $n$ implies use of registers
            \[
            i, i + 1, i + 2, \ldots i + 2^n - 1 .
            \]
            Note that this approach potentially causes an issue wrt.
            registers with specific semantics.  For example, in many
            RISC-like ISAs (including RISC-V), $\GPR[0]$ is fixed to 
            $0$; it may be difficult to include or exclude $\GPR[0]$ 
            in a group as need be.
      \item One could make some register addresses {\em overloaded}.
            For example, ARMv7-A includes a so-called ``unsigned multiply,
            accumulate accumulate'' instruction 
            \VERB{umaal}~\cite[Section A8.8.255]{SCARV:ARMv7_M:17} 
            whose format {\em suggests} $n = 4 = 2 + 2$ but in fact 
            reuses the two destination as additional sources.
      \end{enumerate}
      
      \noindent
      Note that several of these approaches have an implication for the
      difficulty of register allocation; the obvious example is that of
      implicit register addresses.  Likewise, there are various generic
      ways to mitigate the encoding pressure (i.e., the availability of 
      at most $w$ bits) given an approach.  For example one could
      
      \begin{enumerate}
      \item restrict access to some subset of the register file 
            (cf. ARM Thumb or RV32E) 
            thereby reducing the number of bits required to encode each  
            register address,
            or
      \item use some form of instruction prefix.
      \end{enumerate}

\item[Why have a separate register file for \XCID?]
      Versus the alternative case (where \XCID instructions operate on
      the general purpose register file), there are arguments
      for and against a separate register file:
    
      \begin{itemize}
      \item Any extra state, particularly a register file, is expensive in terms of
            sillicon area / resource usage.
      \item Any extra shared state incurs runtime penalties for context switching
            and resource management.
      \item There is a clear separation of concerns between the base RISC-V ISA
            and \XCID. The two sets of instructions need not operate on the same
            state.
            From a security perspective it is even desirable that they do not.
            Similar arguments are made for the floating-point register file in
            the RISC-V F extension.
      \item Separate register files allow more flexibility in how
            \XCID is integrated into a new or existing design. Generally, it
            allows less invasive extension of existing cores, or more
            loosely coupled, re-usable extensions of new cores.
      \item Many \XCID instructions rely on multiple source and destination
            registers. Retrofitting additional read/write ports onto
            existing designs is undesirable. Separation allows each register file
            to be optimised in isolation.
      \item \XCID is designed to enable side-channel resistant designs.
            Dedicated architectural state for secret data allows
            (potentially expensive) hardware countermeasures to be applied only
            to relevant state, rather than the entire pipeline/core.
            Indeed, it raises the possibility of implementing \XCID as an
            entirely separate, {\em secure} processing pipeline.
      \end{itemize}


\item[Why does the \XCID register file have $16$ vs. X entries?]
      The $\XCR$ register file capacity (i.e., the number of constituent
      registers) is a trade-off between quite a number of factors, e.g.,

      \begin{itemize}
      \item increased area, and complexity stemming from implementation
            of the register file,
      \item use of a $16$-element $\XCR$ register file in conjunction
            with RV32E~\cite[Section 3]{SCARV:RV:ISA:I:17} yielding a 
            similar footprint (wrt. this resource at least) to RV32I,
      \item a domain-specific remit suggesting a smaller capacity is 
            viable,
      \item   domain-specific workloads suggest more value from larger 
            registers (i.e., word size), not necessarily larger register
            file capacity,
      \item a smaller capacity reducing instruction encoding pressure.
      \end{itemize}

\item[Why include instruction class $2.1$, when alternative X would be better?]
      Although still further options may be possible, it seems obvious
      that one {\em could} expose the RNG via

      \begin{itemize}
      \item a set of instructions,
      \item one or more CSRs,
            or
      \item a memory-mapped peripheral.
      \end{itemize}

      \noindent
      Trade-offs wrt. various metrics naturally result.  For example,
      the first option demands space in the instruction encoding, 
      whereas
      the last  option can be accessed using existing memory access instructions but with an impact on latency;
      at best, it seems unclear there is a single ``best'' option.

\item[Why include the special purpose class $3.2$ SHA3 instructions?]
      While \XCID tries to include only {\em general purpose} instructions and
      avoid overly specific instructions, in some cases it deviates from this:

      \begin{itemize}
      \item SHA3, and the underlying Keccak round function,
      \item While the compute elements of Keccak are well supported by other
            \XCID instructions (and other proposals in the literature), there
            is considerable latent complexity in generating indices into
            the state matrix.
            This complexity is removed by unrolling the loops and
            turning addresses into constant offsets. However, this is not
            always appropriate in memory constrained environments like embedded
            cores.
      \item The index computation relies on integer arithmetic modulo 5. This
            is very slow to implement using the normal RISC-V {\tt mod} instruction.
            Lookup tables can improve performance at significant energy efficiency cost.
      \item The cost of index computation remains the same across all SHA3 parameter
            sets, meaning that for smaller parameters, it can dominate the runtime.
      \item Code-dense implementations of Keccak which are runtime competitive
            with unrolled versions can bring considerable energy-efficiency
            benefits in systems with instruction caches.
      \item Keccak (particularly the CSHAKE instantiation) is used by many of the
            candidate algorithms submitted to the NIST post-quantum public-key
            cryptography competition. This further increases its importance as
            an optimisation target.
      \item The overhead in terms of resources (LUTs or logic cells) is very
            small compared to the benefits the instructions provide.
      \end{itemize}

\end{description}

% =============================================================================
