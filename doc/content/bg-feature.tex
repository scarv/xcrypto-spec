% =============================================================================

\subsection{Features}
\label{sec:bg:feature}

\begin{table}[t]
\begin{center}
\begin{tabular}{|l|l|cc|}
\hline
Description                                & Class           & Numeric ID & Mnemonic ID \\
\hline\hline
\multirow{1}{*}{Required                 } & Baseline        & $1$        & BASE        \\
\hline
\multirow{5}{*}{Optional, general-purpose} & Randomness      & $2.1$      & RND         \\
                                           & Memory          & $2.2$      & MEM         \\
                                           & Bit-oriented    & $2.3$      & BIT         \\
                                           & Packed          & $2.4$      & PACK        \\
                                           & Multi-precision & $2.5$      & MP          \\
\hline
\multirow{2}{*}{Optional, special-purpose} & AES             & $3.1$      & AES         \\
                                           & SHA3            & $3.2$      & SHA3        \\
\hline
\end{tabular}
\end{center}
\caption{A list of feature classes, plus their associated numeric and mnemonic identifiers.}
\label{tab:feature}
\end{table}

Per \REFSEC{sec:bg:concept}, \XCID is a {\em meta}-extension in that it has 
a) one     required, baseline feature class
   which must {\em always} be supported,
   plus
b) several optional           feature classes
   which can be {\em selectively} supported to suit.
To some extent, this mirrors the extensibility afforded by RV32I itself, 
with similar motivation: doing so allows one to tailor the ISE (resp. ISA) 
st. it suits a given context, which is important because some features are 
applicable within a broad range of cryptographic workloads whereas others 
are (more) specifically applicable (even niche).

The RISC-V naming convention~\cite[Section 22]{SCARV:RV:ISA:I:17} for ISEs
uses a string of single-character identifiers to specify features realised
in an implementation.  We adopt a variant of this approach, wherein
\[
\XCID[$x$/$y$/$z$]
\]
denotes a concrete implementation of \XCID that supports feature classes 
$x$, $y$, and $z$: we assign a numeric and a mnemonic identifier to each
feature class (summarised by \REFTAB{tab:feature}).  For example,
\[
\XCID[1/2.1/2.2/2.3/2.4] ~\equiv~ \XCID[BASE/RND/MEM/BIT/PACK]
\]
describes an implementation which supports
a) the baseline features,
b) features relating to generation of randomness,
c) features relating to advanced memory access, namely scatter/gather
   style store and load operations,
d) features relating to bit-oriented (i.e., Boolean) operations,
   plus
e) features relating to packed (or DSP-like) arithmetic operations:
such an implementation is tailored to suit symmetric cryptography (e.g.,
AES), but {\em not} asymmetric cryptography (e.g., RSA).

% =============================================================================

\subsubsection{Class-$1$:   baseline}
\label{sec:bg:feature:1}

\XCID attempts to avoid unnecessary additional state.  Even so, it {\em does}
introduce

\begin{itemize}
\item $1$ additional register file
      (see \REFSEC{sec:spec:state:xcr}),
      and
\item $2$ additional CSRs 
      (see \REFSEC{sec:spec:state:csr}),
\end{itemize}

\noindent
as a baseline; most of the instructions specified in this class allow access 
to said state.

\subparagraph{Register-register data transfer.}

A suite of instructions
(e.g., \VERB[RV]{xc.gpr2xcr}; see \REFSEC{sec:spec:instruction:xc.gpr2xcr})
that allow 
transfer of content between
the general-purpose register file (i.e., $\GPR$)
and
the    co-processor register file (i.e., $\XCR$)
is included.
In addition, support 
(e.g., \VERB[RV]{xc.cmov.t}; see \REFSEC{sec:spec:instruction:xc.cmov.t})
for conditional, branch'less moves of content between $\XCR$ registers 
(cf. x86 \VERB{cmov}~\cite[Page 3-149--3-152]{SCARV:X86:2:18})
is included; such instructions form a common, vital component
(see, e.g., \cite[Section 5]{SCARV:RFC:7748} wrt. requirement for \VERB{cswap})
in realisations of countermeasures against side-channel attack.

\subparagraph{Register-memory   data transfer.}

A suite of instructions 
(e.g., \VERB[RV]{xc.ld.w} and \VERB[RV]{xc.st.w}; see \REFSEC{sec:spec:instruction:xc.ld.w} and \REFSEC{sec:spec:instruction:xc.st.w})
that allow 
transfer of content between
   memory                         (i.e., $\MEM$)
and
the    co-processor register file (i.e., $\XCR$)
is included.
All such instructions use a base address in $\GPR$, but {\em directly} load 
and store to and from $\XCR$; this avoids having to first load content into 
and then subsequently transfer it from $\GPR$.
Although most are analogous to RV32I, there are some differences: note that

\begin{itemize}
\item variants that support different access granularity (e.g., half-word or
      byte) are included; variants that support updating (or inserting, vs. 
      overwriting) load semantics are also included,
\item matching the context, access is considered to be unsigned throughout;
      there are no sign-extending variants, for example.
\end{itemize}

% =============================================================================

\subsubsection{Class-$2.1$: randomness}
\label{sec:bg:feature:2:1}

Almost all cryptographic workloads have a strong requirement for efficient
generation of high-quality randomness.  This fact stems from use-cases such
as
a) generation of key material, be it ephemeral or long term,
   or
b) implementation of (randomised) countermeasures
   (see, e.g., masking~\cite[Chapter 9]{SCARV:ManOswPop:07}).
Any lack of quality can be outright catastrophic;
for context and (more recent) real-world impact see, e.g.,~\cite{SCARV:KSWH:98,SCARV:RFC:4086} and~\cite{SCARV:NSSKM:17} respectively.
The same is true of efficiency, the lack of which can lead to trade-offs 
that favour execution latency but degrade security.

As a result, many ISAs now include an interface with an underlying (T)RNG
implementation; examples include
x86~\cite[Section 7.3.17.1 and 7.3.17.2]{SCARV:X86:2:18} (see also~\cite{SCARV:JunKoc:99,SCARV:HamKocMar:12})
and
ARMv8.5-A\footnote{
\url{https://community.arm.com/processors/b/blog/posts/arm-a-profile-architecture-2018-developments-armv85a}
}.  \XCID mirrors such designs, including
a suite of instructions 
that allow 
manipulation, e.g.,
 sampling entropy from (via \VERB[RV]{xc.rngsamp}; see \REFSEC{sec:spec:instruction:xc.rngsamp})
or
injecting entropy into (via \VERB[RV]{xc.rngseed}; see \REFSEC{sec:spec:instruction:xc.rngseed})
a (T)RNG implementation.

% -----------------------------------------------------------------------------

\subsubsection{Class-$2.2$: memory}
\label{sec:bg:feature:2:2}

Consider the concept of an S-box (or substitution box), as evident in many 
symmetric primitive designs.  Such an S-box can be described abstractly as 
a Boolean function
\[
\ALG{S-box} : \SET{ 0, 1 }^{n} \rightarrow \SET{ 0, 1 }^{m} ,
\]
st. it substitutes an $n$-bit input for an $m$-bit output.  Both 
the general-case of $n \neq m$
(cf. DES~\cite{SCARV:FIPS:46_3} where $n = 6$ and $m = 4$),
and 
the special-case of $n =    m$
(cf. AES~\cite{SCARV:FIPS:197}  where $n = m = 8$)
are useful in practice, but, either way, the idea is to apply S-box(es) to
some intermediate state to realise some form of confusion step: see, e.g., 
\cite[Section 1.3]{SCARV:KnuRob:11}.
From an implementation perspective, it is common to store each S-box as a
look-up table; although said pre-computation implies some memory overhead
(related to $n$ and $m$), the reduction in (online) computation typically
reduces latency.
However, as outlined by Fiskiran and Lee~\cite{SCARV:FisLee:01}, {\em if}
such an approach is used then the addressing modes available {\em may} be
a factor in any concrete improvement in latency.

This, taken as an exemplar from a richer set of examples, forms motivation
for a richer set of addressing modes than available (by design) in RV32I.
In particular, 
a suite of instructions 
(e.g., \VERB[RV]{xc.scatter.b} and \VERB[RV]{xc.gather.b}; see \REFSEC{sec:spec:instruction:xc.scatter.b} and \REFSEC{sec:spec:instruction:xc.gather.b})
that allow 
scatter/gather-based
transfer of content between
   memory                         (i.e., $\MEM$)
and
the    co-processor register file (i.e., $\XCR$)
is included: the idea is to specify {\em multiple} memory accesses using a
single base address and multiple offsets, and hence scatter sub-words into 
(resp. gather sub-words from) memory at non-contiguous addresses.  
This capability clearly aligns with application of an S-box, with the AES 
{\tt SubBytes}~\cite[Section 5.1.1]{SCARV:FIPS:197} 
round function realised via a single \VERB[RV]{xc.gather.b} instruction 
(albeit multiple resulting memory accesses) given a suitable look-up table.
Couching scatter/gather as a vector-oriented operation, both
\cite[Section 3.1]{SCARV:FouMoo:05} 
and 
\cite[Section 3.3]{SCARV:Fournier:07}
expand on such approach.

% -----------------------------------------------------------------------------

\subsubsection{Class-$2.3$: bit-oriented}
\label{sec:bg:feature:2:3}

Particularly wrt. symmetric primitives, the use of bit-oriented operations 
is common in implementations of cryptography.  At a high level, and though 
counterexamples do exist 
(see, e.g., IDEA~\cite{SCARV:LaiMas:90}, RC6~\cite{SCARV:RRSY:98}),
this fact can be explained by use of alternative (i.e., not word-oriented
and/or not supported by arithmetic in most ISAs) structures and concepts,
and thus operations, in relevant designs.  Associated design rationale may
include
a) security
   (e.g., bit-sliced implementation~\cite{SCARV:KasSch:09} AES~\cite{SCARV:FIPS:197} to mitigate cache-based side-channel attacks),
   or
b) efficiency
   (e.g., use of hardware-friendly bit-permutations in DES~\cite{SCARV:FIPS:46_3}).
As a result, numerous proposals for associated ISEs exist; these typically
act to accelerate in software what would otherwise represent a high (even 
prohibitive) overhead.  \XCID adopts a similar approach, for example, via
support
(e.g., \VERB[RV]{xc.bop}; see \REFSEC{sec:spec:instruction:xc.bop})
for {\em aribitrary} Boolean operations
(cf. x86 \VERB{vpternlogd}~\cite[5-446--5-468]{SCARV:X86:2:18}, and Amiga blitter~\cite[Chapter 6]{SCARV:Amiga:85})
vs. common fixed and so limited instances such as NOT, AND, OR, and XOR.

% -----------------------------------------------------------------------------

\subsubsection{Class-$2.4$: packed}
\label{sec:bg:feature:2:4}

At a high-level, the concept of packed operations can be distilled into two 
central features:

\begin{enumerate}
\item the ability to consider a single $n$-bit register, 
      say $x$, 
      as $l = \frac{n}{w}$ separate $w$-bit sub-words, the $i$-th of which
      we denote
      $
      \INDEX[w]{x}{i} ,
      $
      and
\item the ability to apply an operator,
      say $\odot$,
      across {\em all} $l$ sub-word(s) using a single instruction, e.g.,
      \[
      \INDEX[w]{r}{i} = \INDEX[w]{x}{i} \OP[w]{\odot} \INDEX[w]{y}{i}
      \]
      for $0 \leq i < l$.
\end{enumerate}

\noindent
Note that
a) deliberate use of the term operation is intended to highlight the fact 
   that non-arithmetic operations are viable instances of the same concept,
   and
b) care should be taken to distinguish this concept from traditional vector 
   architectures
   (cf. the Cray X1);
   differences include dedicated support for vector data types, vs. what
   could be viewed as retro-fitting packed sub-words in a scalar data type.
It is common to describe packed arithmetic as an instance of a more general
Single Instruction, Multiple Data (SIMD) model, with the term SIMD Within 
A Register (SWAR) further highlighting specifics of the instantiation.

Concrete examples of support for packed operations include
x86-based~\cite[Section 2.2.7]{SCARV:X86:2:18} MMX, SSE, and AVX,
and
ARM-based DSP (e.g., for lower-end Cortex-M), NEON, and SVE~\cite{SCARV:SBBEEGHMMPRRW:17}.
Such examples are often motivated by use-cases related to, or even marketed 
as solutions for media or signal processing.  Although it is well know that
cryptographic workloads can take advantage of the same functionality
(see, e.g.,~\cite{SCARV:Hamburg:09,SCARV:BerSch:12}),
it is also true that more specific provision can assist doing so; in short,
such provision is the aim of \XCID.  For example, it includes support for
smaller (e.g., $4$-bit) sub-words than normal: this aligns with the demands
of symmetric primitives such as PRESENT~\cite{SCARV:BKLPPRSV:07}.

% -----------------------------------------------------------------------------

\subsubsection{Class-$2.5$: multi-precision}
\label{sec:bg:feature:2:5}

Modular, multi-precision integer arithmetic forms a foundation for various
cryptographic use-cases, but particularly asymmetric primitives; examples 
include
RSA (relying on arithmetic in $\B{Z}_N$ for large $N$),
and
ECC (relying on arithmetic in $\B{F}_p$ for large $p$).
As such, there is a large body of literature on the implementation of said 
arithmetic; this includes support for implementations via ISEs defined for 
RISC-based processors.

\XCID includes a suite of instructions 
(e.g., \VERB[RV]{xc.madd.3}; see \REFSEC{sec:spec:instruction:xc.madd.3})
which mirror low-level steps in higher-level algorithms for multi-precision 
integer arithmetic; in part, these mirror features in 
XS1~\cite[Section 18]{SCARV:XS1:09} 
there termed ``long arithmetic''.  A central design principle is that every
instruction explicitly accepts {\em all} input required: this implies there
is no additional
explicit (e.g., accumulator register) 
nor 
implicit (e.g., status flags for carry or borrow)
state.
Such an approach is particularly attractive when set within the context of 
RV32I, because it avoids inclusion of status flags and so forces (somewhat 
high overhead) software-based carry and overflow management.

% -----------------------------------------------------------------------------

\subsubsection{Class-$3.1$: AES}
\label{sec:bg:feature:3:1}

The 
AES~\cite{SCARV:FIPS:197} 
block cipher is an important, standard component in a range of use-cases.  
Most cryptographic software libraries will include an AES implementation 
as a result of this fact, often supporting multiple 
parameter sets     (e.g., key sizes)
and/or
optimisation goals (e.g., wrt. time or space)
that stem from flexibility afforded by the underlying design.
Focusing on the trade-off between time and space (or area), it is common
to accelerate a software-based AES implementation using bespoke hardware.
Doing so aligns with reduction of latency in use-cases such as ``bulk''
encryption (e.g., of network traffic), and, as such, is supported by a
rich lineage of designs and results (see, e.g., \REFAPPX{appx:related}).

\XCID includes a suite of instructions 
(e.g., \VERB[RV]{xc.aes.sub} and \VERB[RV]{xc.aes.mix}; see \REFSEC{sec:spec:instruction:xc.aessub} and \REFSEC{sec:spec:instruction:xc.aesmix})
drawn directly from the design of
Tillich and Gro{\ss}sch\"{a}dl~\cite{SCARV:TilGro:06}.
The constituent ISE supports a $32$-bit, column-oriented implementation 
of AES, focusing on the
{\tt SubBytes}~\cite[Section 5.1.1]{SCARV:FIPS:197},
{\tt ShiftRows}~\cite[Section 5.1.2]{SCARV:FIPS:197}, 
and
{\tt MixColumns}~\cite[Section 5.1.3]{SCARV:FIPS:197}
round functions.  It does so in a manner than 
a) reduces the latency of executing those round functions, 
   while also
b) eliminating the need for look-up tables and associated memory access
   to them (which is pertinent for some forms of attack vector).

% -----------------------------------------------------------------------------

\subsubsection{Class-$3.2$: SHA3}
\label{sec:bg:feature:3:2}

These instructions are used to create accelerated, code-dense implementations
of the Keccak family of sponge functions used in the SHA3 hash function.

While other classes of \XCID instruction can accelerate the computation
and transformation of the Keccak state array, the SHA3 class of instruction
is used to accelerate state index address generation.

For implementations where code density is a constraint, and loop-unrolling
based performance optimisations are not an option, these instructions
very quickly and compactly compute the indexes into the Keccak state arrays
based on the loop counter variables.

% =============================================================================
